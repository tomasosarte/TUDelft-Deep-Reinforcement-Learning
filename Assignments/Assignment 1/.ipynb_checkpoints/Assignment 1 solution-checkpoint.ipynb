{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "# Load train and test-set\n",
    "train_set = DataLoader(datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor()), \n",
    "                       batch_size=1024, shuffle=True)\n",
    "test_set = DataLoader(datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor()), \n",
    "                      batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of accuracy for categorical data\n",
    "def accuracy(mx, y):\n",
    "    return (mx.max(dim=-1)[1] == y).sum().item() / len(y)\n",
    "\n",
    "# One epoch of the model on test or traning data. If an optimizer is provided, perform gradient descent.\n",
    "def epoch(data, model, optimizer=None):\n",
    "    losses, accuracies = [], []\n",
    "    for x, y in data:\n",
    "        mx = model(x)\n",
    "        loss = criterion(mx, y)\n",
    "        if optimizer is not None: \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(accuracy(mx, y))\n",
    "    return np.mean(losses), np.mean(accuracies)\n",
    "\n",
    "# Train the given model for n epochs\n",
    "def train_model(model, n=10, lr=0.0005):\n",
    "    optimizer = th.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    train_loss, train_acc = [], []\n",
    "    loss, acc = epoch(test_set, model)\n",
    "    test_loss, test_acc = [loss], [acc]\n",
    "    # Main training loop\n",
    "    print('Epoch ', end='')\n",
    "    for e in range(n):\n",
    "        print(e + 1, end=' ')\n",
    "        # Train the model\n",
    "        loss, acc = epoch(train_set, model, optimizer=optimizer)\n",
    "        train_loss.append(loss)\n",
    "        train_acc.append(acc)\n",
    "        # Test the model\n",
    "        loss, acc = epoch(test_set, model)\n",
    "        test_loss.append(loss)\n",
    "        test_acc.append(acc)\n",
    "    print()\n",
    "    return train_loss, train_acc, test_loss, test_acc\n",
    "\n",
    "# Plots the loss and accuracy output of train_model()\n",
    "def plot_learning_curves(train_loss, train_acc, test_loss, test_acc):\n",
    "    def plot_series(train, test, ylabel=''):\n",
    "        gca = plt.gca()\n",
    "        gca.plot([i+1 for i in range(len(train))], train)\n",
    "        gca.plot([i for i in range(len(test))], test)\n",
    "        gca.legend(['train', 'test'])\n",
    "        gca.set_xlabel('training epochs')\n",
    "        gca.set_ylabel(ylabel)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(16, 4)\n",
    "    pl.subplot(1, 2, 1)\n",
    "    plot_series(train_loss, test_loss, 'loss')\n",
    "    pl.subplot(1, 2, 2)\n",
    "    plot_series(train_acc, test_acc, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([784, 10])\n",
      "Epoch 1 torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([608, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([784, 10])\n",
      "2 torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([608, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n",
      "torch.Size([1024, 10])\n"
     ]
    }
   ],
   "source": [
    "# A1.1 (a) ######################################################\n",
    "# MNIST classification network from the lecture slides\n",
    "def make_model():\n",
    "    return th.nn.Sequential(th.nn.Conv2d(1, 8, 5),    # ( 8, 24, 24)\n",
    "                            th.nn.ReLU(),             # ( 8, 24, 24)\n",
    "                            th.nn.MaxPool2d(2, 2),    # ( 8, 12, 12)\n",
    "                            th.nn.Conv2d(8, 16, 5),   # (16,  8,  8)\n",
    "                            th.nn.ReLU(),             # (16,  8,  8)\n",
    "                            th.nn.MaxPool2d(2, 2),    # (16,  4,  4)\n",
    "                            th.nn.Flatten(),          # (16 * 4 * 4)\n",
    "                            th.nn.Linear(256, 128),   # (128)\n",
    "                            th.nn.ReLU(),             # (128)\n",
    "                            th.nn.Linear(128, 32),    # ( 32)\n",
    "                            th.nn.ReLU(),             # ( 32)\n",
    "                            th.nn.Linear(32, 10))     # ( 10)\n",
    "\n",
    "# Define cross-entropy optimization criterion\n",
    "criterion = th.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model and plot\n",
    "plot_learning_curves(*train_model(make_model()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1.1 (b) #########################################################\n",
    "# New cross-entropy optimization criterion\n",
    "def criterion(mx, y):\n",
    "    one_hot = th.zeros(*mx.shape).scatter_(dim=-1, index=y.unsqueeze(dim=-1), src=th.ones(1, 1).expand_as(mx))\n",
    "    return th.nn.functional.mse_loss(mx, one_hot)\n",
    "\n",
    "# Train the model and plot\n",
    "plot_learning_curves(*train_model(make_model()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1.1 (c) #########################################################\n",
    "# CNN for MNIST with one onput neuron\n",
    "def make_model():\n",
    "    return th.nn.Sequential(th.nn.Conv2d(1, 8, 5),    # ( 8, 24, 24)\n",
    "                            th.nn.ReLU(),             # ( 8, 24, 24)\n",
    "                            th.nn.MaxPool2d(2, 2),    # ( 8, 12, 12)\n",
    "                            th.nn.Conv2d(8, 16, 5),   # (16,  8,  8)\n",
    "                            th.nn.ReLU(),             # (16,  8,  8)\n",
    "                            th.nn.MaxPool2d(2, 2),    # (16,  4,  4)\n",
    "                            th.nn.Flatten(),          # (16 * 4 * 4)\n",
    "                            th.nn.Linear(256, 128),   # (128)\n",
    "                            th.nn.ReLU(),             # (128)\n",
    "                            th.nn.Linear(128, 32),    # ( 32)\n",
    "                            th.nn.ReLU(),             # ( 32)\n",
    "                            th.nn.Linear(32, 1))      # (  1)\n",
    "\n",
    "# Transformation function for (d)\n",
    "move, scale = 0, 1\n",
    "def trans(x):\n",
    "    return x * scale + move\n",
    "\n",
    "# New regression criterion (incl. transformation) for scalar predictions\n",
    "def criterion(mx, y):\n",
    "    return th.nn.functional.mse_loss(trans(mx.squeeze()), y.float())\n",
    "\n",
    "# New accuracy definition (incl. transformation) for scalar predictions\n",
    "def accuracy(mx, y):\n",
    "    return ((trans(mx.squeeze()) - y.float()).abs() < 0.5).sum().item() / len(y)\n",
    "\n",
    "# Train new model with new cirterion\n",
    "plot_learning_curves(*train_model(make_model(), n=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1.1 (d) #########################################################\n",
    "move, scale = 4.5, 4.5\n",
    "plot_learning_curves(*train_model(make_model(), n=50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
